{
 "cells": [
  {
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "trusted": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "cell_type": "code",
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import xgboost\n",
    "\n",
    "print('xgboost', xgboost.__version__)"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "xgboost 0.82\n"
     ],
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "['oasis_cross-sectional.csv', 'oasis_longitudinal.csv']\nIndex(['Subject ID', 'MRI ID', 'Group', 'Visit', 'MR Delay', 'M/F', 'Hand',\n       'Age', 'EDUC', 'SES', 'MMSE', 'CDR', 'eTIV', 'nWBV', 'ASF'],\n      dtype='object')\n            Visit     MR Delay         Age        EDUC         SES  \\\ncount  373.000000   373.000000  373.000000  373.000000  354.000000   \nmean     1.882038   595.104558   77.013405   14.597855    2.460452   \nstd      0.922843   635.485118    7.640957    2.876339    1.134005   \nmin      1.000000     0.000000   60.000000    6.000000    1.000000   \n25%      1.000000     0.000000   71.000000   12.000000    2.000000   \n50%      2.000000   552.000000   77.000000   15.000000    2.000000   \n75%      2.000000   873.000000   82.000000   16.000000    3.000000   \nmax      5.000000  2639.000000   98.000000   23.000000    5.000000   \n\n             MMSE         CDR         eTIV        nWBV         ASF  \ncount  371.000000  373.000000   373.000000  373.000000  373.000000  \nmean    27.342318    0.290885  1488.128686    0.729568    1.195461  \nstd      3.683244    0.374557   176.139286    0.037135    0.138092  \nmin      4.000000    0.000000  1106.000000    0.644000    0.876000  \n25%     27.000000    0.000000  1357.000000    0.700000    1.099000  \n50%     29.000000    0.000000  1470.000000    0.729000    1.194000  \n75%     30.000000    0.500000  1597.000000    0.756000    1.293000  \nmax     30.000000    2.000000  2004.000000    0.837000    1.587000  \n              Age        EDUC         SES        MMSE         eTIV  \\\ncount  373.000000  373.000000  354.000000  371.000000   373.000000   \nmean    77.013405   14.597855    2.460452   27.342318  1488.128686   \nstd      7.640957    2.876339    1.134005    3.683244   176.139286   \nmin     60.000000    6.000000    1.000000    4.000000  1106.000000   \n25%     71.000000   12.000000    2.000000   27.000000  1357.000000   \n50%     77.000000   15.000000    2.000000   29.000000  1470.000000   \n75%     82.000000   16.000000    3.000000   30.000000  1597.000000   \nmax     98.000000   23.000000    5.000000   30.000000  2004.000000   \n\n             nWBV         ASF       M/F_F       M/F_M  \ncount  373.000000  373.000000  373.000000  373.000000  \nmean     0.729568    1.195461    0.571046    0.428954  \nstd      0.037135    0.138092    0.495592    0.495592  \nmin      0.644000    0.876000    0.000000    0.000000  \n25%      0.700000    1.099000    0.000000    0.000000  \n50%      0.729000    1.194000    1.000000    0.000000  \n75%      0.756000    1.293000    1.000000    1.000000  \nmax      0.837000    1.587000    1.000000    1.000000  \n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "\n",
    "#data = pd.read_csv(\"../input/oasis_cross-sectional.csv\")\n",
    "data = pd.read_csv('../input/oasis_longitudinal.csv')\n",
    "\n",
    "print(data.columns)\n",
    "print(data.describe())\n",
    "\n",
    "y = data.CDR\n",
    "predictors = [\"M/F\",\"Age\",\"EDUC\",\"SES\",\"MMSE\",\"eTIV\",\"nWBV\",\"ASF\"]\n",
    "XX = data[predictors]\n",
    "X = pd.get_dummies(XX)    # One-hot-encoding to convert categorical data into usable form\n",
    "\n",
    "print(X.describe())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Decision Tree results with different number of leaf nodes:\nMax leaf nodes: 5  \t\t Mean Absolute Error:  0.208839\nMax leaf nodes: 50  \t\t Mean Absolute Error:  0.183534\nMax leaf nodes: 500  \t\t Mean Absolute Error:  0.170213\nMax leaf nodes: 5000  \t\t Mean Absolute Error:  0.170213\nMax leaf nodes: 50000  \t\t Mean Absolute Error:  0.170213\nRandom Forest Results, MAE: 0.173404\nRandom Forest with Cross-Validation, MAE: 0.214112\n",
      "XGBoost Results, MAE: 0.185058\nXGBoost Results with parameters tuning, MAE: 0.181718\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "/home/batman/.local/share/virtualenvs/ocean_alzheimers_demo-E3fo3THC/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n/home/batman/.local/share/virtualenvs/ocean_alzheimers_demo-E3fo3THC/lib/python3.6/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n  warnings.warn(CV_WARNING, FutureWarning)\n/home/batman/.local/share/virtualenvs/ocean_alzheimers_demo-E3fo3THC/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n/home/batman/.local/share/virtualenvs/ocean_alzheimers_demo-E3fo3THC/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n/home/batman/.local/share/virtualenvs/ocean_alzheimers_demo-E3fo3THC/lib/python3.6/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n/home/batman/.local/share/virtualenvs/ocean_alzheimers_demo-E3fo3THC/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n  if getattr(data, 'base', None) is not None and \\\n",
      "/home/batman/.local/share/virtualenvs/ocean_alzheimers_demo-E3fo3THC/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n  if getattr(data, 'base', None) is not None and \\\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(X,y,random_state=0)\n",
    "\n",
    "#Impute missing values after train test split\n",
    "my_imputer = SimpleImputer()\n",
    "train_X_imputed = pd.DataFrame(my_imputer.fit_transform(train_X))\n",
    "test_X_imputed = pd.DataFrame(my_imputer.fit_transform(test_X))\n",
    "\n",
    "# Decision Tree\n",
    "def get_mae(max_leaf_nodes, train_X, test_X, train_y, test_y):\n",
    "    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n",
    "    model.fit(train_X, train_y)\n",
    "    preds_y = model.predict(test_X)\n",
    "    mae = mean_absolute_error(test_y, preds_y)\n",
    "    return(mae)\n",
    "\n",
    "print(\"Decision Tree results with different number of leaf nodes:\")\n",
    "for max_leaf_nodes in [5, 50, 500, 5000,50000]:\n",
    "    my_mae = get_mae(max_leaf_nodes, train_X_imputed, test_X_imputed, train_y, test_y)\n",
    "    print(\"Max leaf nodes: %d  \\t\\t Mean Absolute Error:  %f\" %(max_leaf_nodes, my_mae))\n",
    "\n",
    "# Random Forest\n",
    "forest_model = RandomForestRegressor(random_state=99)\n",
    "forest_model.fit(train_X_imputed, train_y)\n",
    "preds_y = forest_model.predict(test_X_imputed)\n",
    "print(\"Random Forest Results, MAE: %f\" %(mean_absolute_error(test_y, preds_y)))\n",
    "\n",
    "# Random Forest with cross-validation\n",
    "my_pipeline = make_pipeline(SimpleImputer(),RandomForestRegressor(random_state=99))\n",
    "scores = cross_val_score(my_pipeline,X,y,scoring='neg_mean_absolute_error')\n",
    "print('Random Forest with Cross-Validation, MAE: %2f' %(-1 * scores.mean()))\n",
    "\n",
    "# XGBoost\n",
    "my_pipeline = make_pipeline(SimpleImputer(),XGBRegressor())\n",
    "my_pipeline.fit(train_X, train_y)\n",
    "preds_y = my_pipeline.predict(test_X)\n",
    "print(\"XGBoost Results, MAE: %f\" %(mean_absolute_error(test_y, preds_y)))\n",
    "\n",
    "# XGBoost with parameters tuning \n",
    "xgb_model = XGBRegressor(n_estimators=1000)\n",
    "xgb_model.fit(train_X_imputed, train_y, early_stopping_rounds=5, \n",
    "             eval_set=[(test_X_imputed, test_y)], verbose=False)\n",
    "preds_y = xgb_model.predict(test_X_imputed)\n",
    "print(\"XGBoost Results with parameters tuning, MAE: %f\" %(mean_absolute_error(test_y, preds_y)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "collapsed": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "trusted": false
   },
   "cell_type": "code",
   "source": [],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-55ce45ad",
   "language": "python",
   "display_name": "PyCharm (ocean_alzheimers_demo)"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}